# app.py (ENHANCED)
import streamlit as st
import requests
import base64
import uuid
from datetime import datetime
import io

# --------------------------
# CONFIG
# --------------------------
# Put your Gemini key into .streamlit/secrets.toml as:
# GEMINI_API_KEY = "-----"
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except Exception:
    API_KEY = None

if not API_KEY:
    st.error("‚ö†Ô∏è Thi·∫øu GEMINI_API_KEY trong .streamlit/secrets.toml")
    st.stop()

# Default model (can be changed in sidebar)
MODEL_OPTIONS = {
    "Gemini 2.0 Flash (nhanh)": "gemini-2.0-flash",
    "Gemini 2.0 Pro (m·∫°nh)": "gemini-2.0-pro-exp",
    "Gemini 1.5 Flash": "gemini-1.5-flash"
}

SYSTEM_INSTRUCTION = (
    "B·∫°n l√† gia s∆∞ ·∫£o th√¢n thi·ªán, gi·∫£i b√†i cho h·ªçc sinh c·∫•p 2‚Äì3. "
    "Tr√¨nh b√†y r√µ r√†ng, d√πng LaTeX cho c√¥ng th·ª©c khi c·∫ßn. N·∫øu c√≥ ·∫£nh, s·ª≠ d·ª•ng ·∫£nh ƒë·ªÉ gi·∫£i th√≠ch."
)

# --------------------------
# SESSION INIT
# --------------------------
st.set_page_config(page_title="Gia S∆∞ ·∫¢o ‚Äì Minh h·ªça & TTS", layout="wide", page_icon="ü§ñ")
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []   # list of dicts: {"role","text","time","image"(opt)}
if "image_history" not in st.session_state:
    st.session_state.image_history = []  # list of dicts: {"id","question","b64","style","time"}
if "chosen_model" not in st.session_state:
    st.session_state.chosen_model = list(MODEL_OPTIONS.values())[0]
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# --------------------------
# STYLE PROMPTS
# --------------------------
STYLE_PROMPT_MAP = {
    "S∆° ƒë·ªì to√°n h·ªçc (diagram)": "diagram-style, clear labels, vector lines, simple shapes, white background, black axis lines",
    "Minh h·ªça ƒë∆°n gi·∫£n (simple illustration)": "flat simple illustration, clean colors, educational style, minimal text, clear shapes",
    "Tranh ho·∫°t h√¨nh (cartoon)": "cartoon style, friendly characters, colorful, playful, simplified shapes",
    "Phong c√°ch s√°ch gi√°o khoa (textbook style)": "textbook illustration, clear labeled parts, muted colors, high clarity",
    "·∫¢nh th·∫≠t (realistic)": "photo-realistic, realistic lighting, natural textures, high resolution"
}

# --------------------------
# HELPERS: Gemini endpoints
# --------------------------
def text_api_url(model):
    return f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}"

# --------------------------
# CALL GEMINI TEXT (generateContent)
# --------------------------
def call_gemini_text(model, user_prompt, image_b64_inline=None):
    url = text_api_url(model)
    # Build contents: system + user parts (optionally inline image)
    contents = [
        {"role": "user", "parts": [{"text": SYSTEM_INSTRUCTION}]}
    ]

    parts = []
    if image_b64_inline:
        # include inline image in request so model can reference it
        parts.append({"inlineData": {"mimeType": "image/png", "data": image_b64_inline}})
    parts.append({"text": user_prompt})
    contents.append({"role": "user", "parts": parts})

    payload = {"contents": contents}

    try:
        res = requests.post(url, json=payload, timeout=45)
    except Exception as e:
        return None, f"L·ªói k·∫øt n·ªëi API (text): {e}"

    if res.status_code != 200:
        return None, f"API text tr·∫£ l·ªói {res.status_code}: {res.text[:300]}"

    try:
        data = res.json()
    except Exception as e:
        return None, f"L·ªói decode JSON (text): {e}. Raw: {res.text[:200]}"

    # Extract text
    try:
        text = data["candidates"][0]["content"]["parts"][0]["text"]
        return text, None
    except Exception as e:
        return None, f"L·ªói ƒë·ªçc ph·∫£n h·ªìi t·ª´ API: {e}"

# --------------------------
# CALL GEMINI IMAGE (via generateContent -> media)
# --------------------------
def call_gemini_image(model, prompt):
    url = text_api_url(model)
    payload = {
        "contents": [
            {"role": "user", "parts": [{"text": prompt}]}
        ]
    }
    try:
        res = requests.post(url, json=payload, timeout=90)
    except Exception as e:
        return None, f"L·ªói k·∫øt n·ªëi API (image): {e}"

    if res.status_code != 200:
        return None, f"API image tr·∫£ l·ªói {res.status_code}: {res.text[:300]}"

    try:
        data = res.json()
    except Exception as e:
        return None, f"L·ªói decode JSON (image): {e}. Raw start: {res.text[:300]}"

    # Look for media in parts
    try:
        parts = data["candidates"][0]["content"]["parts"]
        for p in parts:
            if "media" in p and isinstance(p["media"], dict):
                # media.data is base64 bytes for image/png
                return p["media"]["data"], None
        return None, "Kh√¥ng t√¨m th·∫•y tr∆∞·ªùng media trong ph·∫£n h·ªìi."
    except Exception as e:
        return None, f"L·ªói ƒë·ªçc media t·ª´ response: {e}"

# --------------------------
# TEXT-TO-SPEECH (gTTS)
# --------------------------
def speak_text(text):
    try:
        from gtts import gTTS
        tts = gTTS(text=text, lang="vi")
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        st.audio(fp.read(), format="audio/mp3")
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ t·∫°o gi·ªçng n√≥i (gTTS). L·ªói: " + str(e))

# --------------------------
# UI: SIDEBAR CONTROLS
# --------------------------
with st.sidebar:
    st.title("‚öôÔ∏è C√†i ƒë·∫∑t")
    chosen_label = st.selectbox("Ch·ªçn model Gemini", list(MODEL_OPTIONS.keys()))
    st.session_state.chosen_model = MODEL_OPTIONS[chosen_label]
    st.markdown("---")
    st.subheader("·∫¢nh minh h·ªça")
    style = st.selectbox("Phong c√°ch ·∫£nh", list(STYLE_PROMPT_MAP.keys()))
    extra = st.text_input("Ghi ch√∫ th√™m cho ·∫£nh (t√πy ch·ªçn)", placeholder="v√≠ d·ª•: 'no text, white background'")
    st.markdown("---")
    st.subheader("T√≠nh nƒÉng")
    tts_enabled = st.checkbox("B·∫≠t Text-to-Speech (gTTS)", value=False)
    st.markdown("Phi√™n b·∫£n app: enhanced with image + TTS + history")

# --------------------------
# QUICK SUGGESTIONS (small buttons)
# --------------------------
st.sidebar.markdown("---")
st.sidebar.subheader("G·ª£i √Ω nhanh")
if st.sidebar.button("Gi·∫£i ƒë·ªãnh l√Ω Py-ta-go"):
    st.session_state.user_input = "H√£y gi·∫£i v√† minh h·ªça ƒë·ªãnh l√Ω Pythagore b·∫±ng v√≠ d·ª• tam gi√°c vu√¥ng."
if st.sidebar.button("V√≠ d·ª• b√†i to√°n th·ª±c t·∫ø"):
    st.session_state.user_input = "M·ªôt c√¢y cao c√≥ b√≥ng d√†i 5m. M·ªôt c√¢y kh√°c cao 3m c√≥ b√≥ng 2m. H·ªèi chi·ªÅu cao c√¢y kia l√† bao nhi√™u?"

# --------------------------
# MAIN UI
# --------------------------
st.markdown("<h1 style='text-align:center'>üë®‚Äçüè´ Gia S∆∞ ·∫¢o ‚Äì Minh h·ªça & Thuy·∫øt tr√¨nh</h1>", unsafe_allow_html=True)
col_left, col_right = st.columns([3,2])

with col_left:
    st.subheader("Nh·∫≠p ƒë·ªÅ b√†i / c√¢u h·ªèi")
    user_q = st.text_area("Nh·∫≠p ƒë·ªÅ b√†i ho·∫∑c c√¢u h·ªèi:", value=st.session_state.get("user_input",""), height=160)
    st.session_state.user_input = user_q

    row1, row2 = st.columns([1,1])
    with row1:
        btn_send = st.button("G·ª≠i & Sinh ·∫£nh")
    with row2:
        btn_only_image = st.button("Ch·ªâ sinh ·∫£nh minh h·ªça")

with col_right:
    st.subheader("Nh·∫≠t k√Ω nhanh")
    st.markdown("- L·ªãch s·ª≠ l·ªùi gi·∫£i v√† ·∫£nh s·∫Ω l∆∞u trong phi√™n n√†y.")
    st.markdown("- T·∫£i ·∫£nh ƒë·ªÉ ch√®n slide ho·∫∑c n·ªôp b√°o c√°o.")
    if st.button("ƒê·ªçc tr·∫£ l·ªùi cu·ªëi (TTS)") and tts_enabled:
        # find last assistant text
        for msg in reversed(st.session_state.chat_history):
            if msg["role"] == "assistant" and msg.get("text"):
                speak_text(msg["text"])
                break

# --------------------------
# ACTION: Only Image
# --------------------------
def store_image_entry(question_text, img_b64, style_key):
    img_id = str(uuid.uuid4())
    st.session_state.image_history.append({
        "id": img_id,
        "question": question_text,
        "b64": img_b64,
        "style": style_key,
        "time": datetime.utcnow().isoformat()
    })
    return img_id

if btn_only_image and user_q.strip():
    # build image prompt
    style_desc = STYLE_PROMPT_MAP.get(style, "")
    img_prompt = f"Create an educational, {style} illustration. {style_desc}. Illustrate the following problem clearly for middle school students: {user_q}."
    if extra:
        img_prompt += " Additional instructions: " + extra

    with st.spinner("üé® AI ƒëang sinh ·∫£nh minh h·ªça ‚Äî vui l√≤ng ch·ªù (c√≥ th·ªÉ 10‚Äì30s)..."):
        img_b64, img_err = call_gemini_image(st.session_state.chosen_model, img_prompt)

    if img_err:
        st.error("‚ùå L·ªói khi sinh ·∫£nh: " + img_err)
    else:
        # store and show
        store_image_entry(user_q, img_b64, style)
        st.success("‚úÖ ·∫¢nh minh h·ªça ƒë√£ t·∫°o xong.")
        st.image(base64.b64decode(img_b64), use_column_width=True)
        st.download_button("üì• T·∫£i ·∫£nh minh h·ªça", data=base64.b64decode(img_b64), file_name="minh_hoa.png", mime="image/png")

# --------------------------
# ACTION: Send & Image
# --------------------------
if btn_send and user_q.strip():
    # 1) Call text
    with st.spinner("‚è≥ ƒêang t·∫°o l·ªùi gi·∫£i (AI)..."):
        answer_text, err = call_gemini_text(st.session_state.chosen_model, user_q)
    if err:
        st.error(err)
    else:
        # append to history
        st.session_state.chat_history.append({"role": "user", "text": user_q, "time": datetime.utcnow().isoformat()})
        st.session_state.chat_history.append({"role": "assistant", "text": answer_text, "time": datetime.utcnow().isoformat()})

        # show text immediately
        st.markdown("### üìò L·ªùi gi·∫£i")
        st.markdown(answer_text)

        # optional TTS
        if tts_enabled:
            with st.spinner("üîä ƒêang t·∫°o gi·ªçng n√≥i..."):
                speak_text(answer_text)

        # 2) create image
        style_desc = STYLE_PROMPT_MAP.get(style, "")
        img_prompt = f"Create an educational, {style} illustration. {style_desc}. Illustrate the following problem clearly for middle school students: {user_q}."
        if extra:
            img_prompt += " Additional instructions: " + extra

        with st.spinner("üé® AI ƒëang sinh ·∫£nh minh h·ªça..."):
            img_b64, img_err = call_gemini_image(st.session_state.chosen_model, img_prompt)

        if img_err:
            st.warning("Kh√¥ng t·∫°o ƒë∆∞·ª£c ·∫£nh: " + img_err)
        else:
            # store and attach to the assistant message
            store_image_entry(user_q, img_b64, style)
            st.image(base64.b64decode(img_b64), use_column_width=True)
            st.download_button("üì• T·∫£i ·∫£nh minh h·ªça", data=base64.b64decode(img_b64), file_name="minh_hoa.png", mime="image/png")
            # also attach b64 to last assistant message for history view
            st.session_state.chat_history[-1]["image"] = base64.b64decode(img_b64)

# --------------------------
# SHOW HISTORY (chat + images)
# --------------------------
st.markdown("---")
left_col, right_col = st.columns([3,1])
with left_col:
    st.header("üí¨ L·ªãch s·ª≠ tr√≤ chuy·ªán")
    if not st.session_state.chat_history:
        st.info("Ch∆∞a c√≥ l·ªùi gi·∫£i n√†o. Nh·∫≠p ƒë·ªÅ b√†i v√† b·∫•m 'G·ª≠i & Sinh ·∫£nh'.")
    else:
        for m in st.session_state.chat_history[-12:]:
            if m["role"] == "user":
                st.markdown(f"<div style='text-align:right'><b>üßë‚Äçüéì B·∫°n:</b> {m['text']}</div>", unsafe_allow_html=True)
            else:
                st.markdown(f"<div style='text-align:left'><b>ü§ñ Gia s∆∞ ·∫£o:</b> {m['text']}</div>", unsafe_allow_html=True)
                if m.get("image"):
                    st.image(m["image"], use_column_width=True)

with right_col:
    st.header("üìÇ Nh·∫≠t k√Ω ·∫£nh")
    if not st.session_state.image_history:
        st.info("Ch∆∞a c√≥ ·∫£nh minh h·ªça n√†o.")
    else:
        # show latest 6
        for entry in reversed(st.session_state.image_history[-12:]):
            st.image(base64.b64decode(entry["b64"]), width=160)
            st.write(f"üìù {entry['question'][:80]}{'...' if len(entry['question'])>80 else ''}")
            st.write(f"- Phong c√°ch: {entry['style']}")
            st.write(f"- Th·ªùi gian: {entry['time']}")
            st.download_button("T·∫£i ·∫£nh", data=base64.b64decode(entry["b64"]), file_name=f"minh_hoa_{entry['id']}.png", mime="image/png")
            st.markdown("---")

# --------------------------
# FOOTER
# --------------------------
st.markdown("---")
st.caption("Ghi ch√∫: Ki·ªÉm tra quy·ªÅn s·ª≠ d·ª•ng ·∫£nh n·∫øu s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch th∆∞∆°ng m·∫°i. ·ª®ng d·ª•ng s·ª≠ d·ª•ng API Gemini (Google).")
